# Whisper model settings
# WHISPER_MODEL=medium.en
# WHISPER_MODEL=small.en
# WHISPER_MODEL=tiny.en
WHISPER_MODEL=medium.en
COMPUTE_TYPE=int8

# Inference/VAD defaults (overridable per request)
# Enable VAD filtering to drop low-energy segments
VAD_ENABLED=true
# Minimum silence duration between speech (ms)
VAD_MIN_SILENCE_MS=300
# Decoder thresholds to be less strict about speech detection
NO_SPEECH_THRESHOLD=0.3
LOGPROB_THRESHOLD=-1.0

# Speaker Diarization Settings
USE_SPEAKER_DIARIZATION=true
# Diarization mode: auto | offline | online
# - offline: use local cache only (no internet)
# - online: fetch from HF (requires HUGGINGFACE_TOKEN and accepted model terms)
# - auto: try offline first, then online if token available
DIARIZATION_MODE=auto
# HUGGINGFACE_TOKEN is optional when using fully offline diarization
# Get your token from https://huggingface.co/settings/tokens if you need online access
# HUGGINGFACE_TOKEN=your_huggingface_token_here

# Pyannote settings - Using specific version for better performance
PYANNOTE_SEGMENTATION_MODEL=pyannote/speaker-diarization-3.1
# Base local path only; the app resolves the actual snapshot via refs/main
PYANNOTE_SEGMENTATION_MODEL_LOCAL_PATH=~/.cache/huggingface/pyannote/sd3.1/pyannote-models/models--pyannote--speaker-diarization-3.1

# Output Format
# Set to 'true' to include timestamps in the transcript, 'false' to exclude them
SHOW_TIMESTAMPS=false

# Meeting Notes - Ollama Settings
# Available models: gpt-oss:20b, llama2:13b, mistral, etc.
OLLAMA_MODEL=llama2:13b  # Change this to use a different Ollama model
OLLAMA_BASE_URL=http://localhost:11434

# File Upload Settings
MAX_FILE_SIZE=52428800  # 50MB in bytes

# Logging Settings
LOG_LEVEL=INFO

# Recordings base directory (allow-list for server-local paths)
# Prefer setting this to where your recording/stop step writes files.
# If unset, defaults to the app's `intermediate` directory.
# New name:
# RECORDINGS_ROOT=backend/intermediate
# Backward compatible legacy name (still supported):
# WORKSPACE_ROOT=backend/intermediate

# --- Local Recording / Mixing Configuration ---
# Whether to write mixed.wav live during recording (spawns a third ffmpeg).
# Possible values: true | false
RECORDING_USE_LIVE_MIX=true

# Mixed output policy when creating mixed.wav
# - separation: stereo with mic=Left, system=Right (good for analysis)
# - audible_mix: both inputs mixed to stereo center with -3 dB headroom each
# Possible values: separation | audible_mix
RECORDING_MIX_POLICY=separation

# Display name of the BlackHole device to look up via avfoundation device list
# Override if you use a different virtual device name
# Example values: "BlackHole 2ch" | "BlackHole 16ch" | your custom name
BLACKHOLE_DEVICE_NAME=BlackHole 2ch

# Sample rate used when capturing via ffmpeg (Hz)
# Common values: 48000 | 44100
RECORDING_SAMPLERATE=48000

# Optional explicit device index overrides (use if auto-detect picks wrong devices)
# RECORDING_MIC_INDEX=3
# RECORDING_BLACKHOLE_INDEX=2
# Prefer mic device names including this hint (case-insensitive)
RECORDING_MIC_NAME_HINT=Microphone
# Comma-separated substrings to ignore when selecting mic devices
RECORDING_IGNORE_INPUTS=ZoomAudioDevice,Teams,Virtual,Camera
