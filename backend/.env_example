# Whisper model settings
# WHISPER_MODEL=medium.en
# WHISPER_MODEL=small.en
# WHISPER_MODEL=tiny.en
WHISPER_MODEL=medium.en
COMPUTE_TYPE=int8

# Speaker Diarization Settings
USE_SPEAKER_DIARIZATION=true
# Diarization mode: auto | offline | online
# - offline: use local cache only (no internet)
# - online: fetch from HF (requires HUGGINGFACE_TOKEN and accepted model terms)
# - auto: try offline first, then online if token available
DIARIZATION_MODE=auto
# HUGGINGFACE_TOKEN is optional when using fully offline diarization
# Get your token from https://huggingface.co/settings/tokens if you need online access
# HUGGINGFACE_TOKEN=your_huggingface_token_here

# Pyannote settings - Using specific version for better performance
PYANNOTE_SEGMENTATION_MODEL=pyannote/speaker-diarization-3.1
# Base local path only; the app resolves the actual snapshot via refs/main
PYANNOTE_SEGMENTATION_MODEL_LOCAL_PATH=~/.cache/huggingface/pyannote/sd3.1/pyannote-models/models--pyannote--speaker-diarization-3.1

# Output Format
# Set to 'true' to include timestamps in the transcript, 'false' to exclude them
SHOW_TIMESTAMPS=false

# Meeting Notes - Ollama Settings
# Available models: gpt-oss:20b, llama2:13b, mistral, etc.
OLLAMA_MODEL=llama2:13b  # Change this to use a different Ollama model
OLLAMA_BASE_URL=http://localhost:11434

# File Upload Settings
MAX_FILE_SIZE=52428800  # 50MB in bytes

# Logging Settings
LOG_LEVEL=INFO
